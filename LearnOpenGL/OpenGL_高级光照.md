w# OpenGL高级光照
```toc
```

#### 高级光照
- Phong与Blinn-Phong
	- Phong在视方向和光反射方向的夹角大于90°的情况下会出现问题：(这个问题的具体原因没想明白， 待补充)<br>![[OpenGL_Phong问题.png]]
	- **Blinn-Phong：使用半程向量。视方向越接近光反射方向的时候，镜面高光就会越强**
		- 半程向量：normalize(视方向+**光**方向)
	- Blinn-Phong和Phong的唯一区别是，Blinn-Phong测量的是法线和半程向量之间的夹角，而Phong测量的是观察方向与反射向量间的夹角
	- 由于半程向量和法线的夹角通常会小于视方向和光反射方向的夹角，所以如果想让Blinn-Phong和Phong产生差不多的结果，需要把Blinn-Phong的反光度设置为使用Phong时的2-4倍
		- ![[OpenGl_Phong-Blinn-Phong效果对比.png]]

#### Gamma校正
- ###### Gamma校正的理解
	- **个人理解：Gamma校正发生在把该让显示器显示的颜色输出给显示器之前。由于显示器为了显示更适合人眼的亮度范围，在显示画面的时候会把本该输出的颜色做一次幂运算(现代显示器的幂通常为2.2)，使得暗部的色阶更多，而压缩了亮部的色阶，因为人眼对于暗部的色阶感知更敏感，而对于亮部的色阶感知要弱很多。而在Shader里得到的颜色值是基于线性Gamma(Gamma值为1)的，如果不对输出给显示器的结果做Gamma校正，那么显示器显示的结果将和理想中的结果不一样。所以为了得到理想的(Gamma为1)的显示结果，需要对要输出给显示器的颜色做一次反函数(即幂为1/2.2)，来使最终显示器显示的颜色符合线性空间的颜色**
	- Gamma校正就是对颜色进行指数运算。对图像进行校正是为了获得复合人眼特性的可辨识精度。矫正使用的Gamma 值取决于显示器，现代系统基本上都统一使用2.2。
	- 由于阴极射线管显示器(CRT)的物理特性，输入的电压不直接等于显示的亮度，而是一个电压的**次幂**，这个次幂数就是Gamma值(也叫灰度系数)。对于CRT来说，Gamma通常是2.2，也就是**屏幕显示的亮度是输入电压的2.2次幂**
	- **线性空间：** Gamma为1的理想状态
	- - 人眼对亮度的感知 VS 物理上的亮度变化：
		- ![[OpenGL_亮度对比.png]]
		- 人眼对于暗部的变化更加敏感，更能区分暗部的色阶，而对于亮部的色阶却不是很敏感
		- 物理正确的亮度的亮色部分会精度过剩而暗色部分会精度不足，所以显示器会把物理正确的亮度映射为适合人眼感知的亮度
	- ![[OpenGL_Gamma校正图.png]]
		- 点函数是线性空间 (Gamma值为1的理想情况)的0-1的亮度
		- 实线函数是显示器实际显示的亮度
		- 线段函数是输入给显示器的亮度
		- **由于显示器的Gamma值和Gamma校正互为反函数，他们结合在一起最终的显示结果将会是线性空间的亮度，即点函数的值**
	- **2.2这个值：** 2.2通常是大多数显示设备的平均Gamma值。基于Gamma2.2的颜色空间叫**sRGB颜色空间**。每个显示器的Gamma曲线都不一样，但是2.2在大多数显示器上的表现都还行
- ###### 在OpenGL里应用Gamma校正
	- 开启sRGB帧缓冲
		- <mark>glEnable(GL_FRAMEBUFFER_SRGB)</mark>
		- 开了之后什么都不用管了，OpenGL将自动执行Gamma校正(幂值2.2)
	- 给着色器的最终输出(return)做Gamma校正
		- <mark>pow(FinalRGB, vec3(1.0/Gamma))</mark>
		- 好处是可以更改Gamma值，但是需要给每个片段着色器都加上Gamma校正。或者也可以使用后处理，在后处理的图像上进行一次Gamma校正
	- **因为Gamma校正会把颜色从线性空间转变为非线性空间，所以需要在最最最后的一步，在输出给显示器画面的前一刻，做Gamma校正，否则在Gamma校正后进行的计算所得到的结果将会是错的**
- ###### sRGB纹理
	- 在sRGB空间下创建的纹理已经应用了Gamma校正，如果再对他们的计算结果进行Gamma校正的话就校正了两次，结果就不对了。
		- 可以通过<mark>glTexImage2D(GL_TEXTURE_2D, 0, GL_SRGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, image);</mark>来把sRGB空间的纹理变换为线性空间
	- 也可以在片段着色器所有的计算开始之前把纹理应用一次Gamma
		- <mark>float gamma = 2.2; <br>vec3 diffuseColor = pow(texture(diffuse, texCoords).rgb, vec3(gamma));</mark>
	- *并不是所有纹理都是sRGB空间。为物体上色的纹理基本上都是在sRGB空间中，而为了获取光照参数的纹理(Grayscale)基本上都是在线性空间中*
- ###### 衰减
	- 在不使用Gamma校正的时候，<mark>float attenuation = 1.0 / distance</mark>看起来更真实，因为在不使用Gamma校正时，实际显示的画面是(1.0/distance)<sup>2.2</sup>,也就是1.0/distance<sup>2.2</sup>，他更接近物理正确的光照衰减公式
	- 而使用了Gamma校正之后，物理正确的光照公式<mark>float attenuation = 1.0 / (distance * distance)</mark>则更加真实，因为最终显示的结果被变换到了线性空间
	- 这个公式在使用Gamma校正的场景也能用，因为他可以给予更多对于光照的控制权<br>![[OpenGL_光源衰减公式.png]]
- ###### 使用Gamma校正和不使用的对比
	- 不使用Gamma校正<br>![[OpenGL_不使用Gamma校正.png]]
	- 使用Gamma校正<br>![[OpenGL_使用Gamma校正.png]]

#### 法线贴图
- 法线用于为模型表达更多的细节。由于法线是垂直于表面的，方向各异的法线会表现为模型拥有更多的细节，更多的面
- 每个片段通过对Normal Map的采样得到自己的法线，而不是使用插值表面法线，并通过光照计算得到该片段在当前光照环境下的颜色，最终输出到颜色缓冲
- ###### 法线贴图
	- 法线贴图为每个片段储存了他对应的法线方向。2D贴图的颜色范围在\[0, 1]的范围之间，而法线向量的范围在\[-1, 1]之间。所以在**将法线方向信息储存到2D纹理中时，需要把\[-1, 1]的范围映射到\[0, 1]的范围**
		- <mark>vec3 rgb_normal = normal * 0.5 + 0.5;</mark>
	- ![[OpenGL_法线贴图.png]]
		- 法线贴图会是这个颜色的原因是，法线贴图储存的是每个像素的切线空间下的法线方向，切线空间下法线每个坐标轴的取值范围在\[-1, 1]之间，而映射到2D纹理所需的\[0, 1]的范围之后，原本的Z方向(0, 0, 1)就变成了(0.5, 0.5, 1)，呈紫蓝色
		- 紫蓝色(128, 128, 255)<br>![[OpenGL_法线颜色.png]]
- ###### 切线空间
	- 切线空间解决了当模型的一些面不朝向正Z方向时，模型对于法线贴图采样出的法线不正确的问题 (比如模型的一个面朝向正Y反向，但是从法线贴图中采样出的法线信息是朝正Z方向的，那么光照计算的结果就会是错的)
	- 切线空间是位于模型三角形表面之上的空间，切线空间下的法线永远指向正Z方向，永远垂直于三角形表面
	- 通过**TBN矩阵**将切线空间的法线变换到世界空间
		- T：Tangent
		- B：Bitangent
		- N：Normal
		- *切线和副切线的推导计算寄了，没看懂，但是在导入模型到引擎的时候引擎会计算切线和副切线并可以在顶点着色器中获取，所以问题不大-_-*
		- *TBN \* 向量是将向量从世界空间变换到切线空间*
		- *向量 \* TBN是将向量从切线空间变换到世界空间*
	- [在Unity中计算TBN](https://zhuanlan.zhihu.com/p/389680745)
	- **两种使用TBN的方法**
		- 1. 将法线贴图存储的切线空间下的法线变换到世界空间
			- 在顶点着色器中获取顶点的T、B、N，将他们**变换到世界空间**，并把他们组合成3x3的矩阵传递给片段着色器<br>![[OpenGL_TBN矩阵.png]]
			- 在片段着色器中将从法线贴图中采样到的法线信息**映射回\[-1, 1]的范围**，然后使用TBN矩阵与映射后的法线信息相乘<br>![[OpenGL_应用TBN矩阵.png]]
		- 2. 将需要使用到法线信息的计算的其他向量变换到切线空间与法线进行计算
			- *这个方法的好处是由于顶点着色器绝大多数情况下都比片段着色器运行的少，将向量都在顶点着色器中变换到切线空间计算光照信息可以很好的节省性能*
			- 在顶点着色器中计算TBN矩阵的逆矩阵并传递给片段着色器<br><mark>vs_out.TBN = transpose(mat3(T, B, N));</mark>
				- *TBN矩阵是正交矩阵，正交矩阵的逆矩阵与它的转置矩阵相等，而矩阵转置的开销比矩阵求逆的开销要小，所以使用转置矩阵代替逆矩阵来获得一样的效果*
			- 在片段着色器中将需要用到的其他向量使用转置后的TBN矩阵变换到切线空间后，进行光照计算<br>![[OpenGL_应用TBN矩阵切线空间.png]]
- TBN矩阵重正交化
	- 当在更大的网格上计算切线向量的时候，它们往往有很大数量的共享顶点，当法向贴图应用到这些表面时将切线向量平均化通常能获得更好更平滑的结果。这样做有个问题，就是TBN向量可能会不能互相垂直，这意味着TBN矩阵不再是正交矩阵了
	- 使用叫做_格拉姆-施密特_正交化过程（Gram-Schmidt process）的数学技巧，我们可以对TBN向量进行重正交化，这样每个向量就又会重新垂直了。在顶点着色器中我们这样做：
	- ![[OpenGL_TBN重正交化.png]]

#### 视差贴图(Paralax Mapping)
- 视差贴图用于表现表面的深度
- 视差贴图通过修改一个片段的纹理坐标使得他看起来比实际要更高或者更低
- ###### 原理
	- ![[OpenGL_视差贴图原理1.png]]
	- 黑色平面是模型实际的表面
	- 红线是在Height Map中表示的高度
	- V是从`A`到`相机`的观察方向
	- 视差贴图的目的是，在`A`位置的的片段不再使用`A`的纹理坐标而是使用`B`的，再对`B`的纹理坐标采样后，就像看到了`B`点一样
	- ![[OpenGL_视差贴图原理2.png]]
	- 方法是将视方向根据片段`A`的高度进行缩放，然后根据缩放过后的向量的与纹理表现平行的分量(x, y分量)来对片段的纹理坐标进行偏移
	- 视差计算根据点`A`的高度值对(单位向量)视方向进行缩放，来得到点`P`的纹理坐标值
	- `P`的值是`B`的近似值，只是一个大概的值
	- 这个计算需要在切线空间下进行，经过变换的`P`向量的x和y将于表面的切线和副切线向量对齐。而又由于切线和副切线向量与表面纹理坐标的方向相同，就可以用`P`的x和y分量作为纹理坐标的偏移量而不用考虑表面的方向了
- ###### 视差贴图的应用
	- 视差贴图与高度图是**相反的**，高度图表示的是每个像素的高度，颜色越白，代表像素越高，视差贴图表示的是每个像素的深度，颜色越白，代表像素越深(低于当前平面)，这样做是因为模拟深度比模拟高度更容易
		- *仍然可以使用把高度图当做深度图来用，在Shader里1-高度图就行了*
	- ![[OpenGL_视差贴图原理3.png]]
	- `A`：在平面上实际看到的点
	- `B`：希望能看到的点
	- `P`：实际采样的点，`B`的近似值
- ###### 陡峭视差映射(Steep Parallax Mapping)
	- ![[OpenGL_陡峭视差映射.png]]
	- 将总深度范围划分出多个层级。从每个层中沿着`P`方向移动采样纹理坐标，知道找到一个采样低于当前层的深度值
- ###### 视差遮蔽映射
	- 用于解决陡峭视差映射的一层一层的效果
		- 有两种流行的解决方法：
			- Relief Parallax Mapping ：更精确，但是开销很大
			- Parallax Occlusion Mapping (视差遮蔽映射)：效果和Relief Parallax Mapping差不多但是开销小很多
	- 与陡峭视差映射不同的是，视差遮蔽映射不是用的触碰的第一个深度层的纹理坐标，而是在触碰之前和之后，在深度值之间进行Lerp，根据**表面的高度值**距离**前后两个高度层**的**距离值**进行插值
	- ![[OpenGL_视差遮蔽映射.png]]
	- 代码：<br>![[OpenGL_视差贴图代码.png]]![[OpenGL_视差贴图代码2.png]]

#### HDR
- **HDR的优点：**
	- 在明亮和黑暗区域无细节损失，因为他们可以通过色调映射重新获得
	- 多个光照的叠加不会导致亮度被截断的区域的出现，光照可以被设定为他们原来的亮度值而不是被LDR值限制
	- 可以使用Bloom来达到更nice的效果
- ·HDR用来表现更大的光照动态范围，让光照亮度能够超过1，并且能同时保留暗部和亮部的细节
- 由于显示器只能显示\[0, 1]范围内的值，所以HDR的值需要经过**色调映射(Tone Mappng)**
来将颜色映射到\[0, 1]的范围内
- 如果不使用HDR，并且场景里有多个光源叠加，使得片段的颜色超过1，那么这些片段的颜色值会被约束在1，使场景中大量的片段的颜色都为1或者接近1，让整个场景糊成一片丢失细节
- ###### 浮点帧缓冲
	- 当一个**帧缓冲**的**颜色缓冲**的的内部各式被设定为了`GL_RGB16F`、`GL_RGBA16F`、`GL_RGB32F`或者`GL_RGBA32F`时，该帧缓冲被叫做浮点帧缓冲
	- **浮点帧缓冲(Floating Point Framebuffer)** 可以储存超过\[0, 1]范围的值，适合用于HDR渲染
	- 在创建帧缓冲时将颜色缓冲的内部格式改为`GL_RGB16F`即可创建一个浮点帧缓冲
		- 默认的帧缓冲一个颜色只占8位(\[0, 255])，除非真的需要非常高的精度，不然32位不是必须的，使用`GL_RGB16F`就够了
	- <mark>glBindTexture(GL_TEXTURE_2D, colorBuffer); <br>glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_FLOAT, NULL);</mark>
	- 如果直接将浮点帧缓冲的结果传给默认帧缓冲并输出给屏幕，那么在浮点帧缓冲上超过1的颜色还是会被约束在1，相当于跟只是用默认帧缓冲没有区别。需要在发送给默认帧缓冲并输出到屏幕之前对浮点帧缓冲的值做**色调映射**来将他们变换到\[0, 1]的范围内
	- ![[OpenGL_HDR结果_无色调映射.png]]
- ###### 色调映射
	- 将HDR的浮点值转换到LDR的\[0, 1]的范围内
	- **Reinhard色调映射**
		- HDR的所有值在LDR都有对应，他平均的将所有亮度值分散到LDR上
		- <mark>vec3 toneMapped = hdrCol / (hdrCol + vec3(1.0))</mark>
		- Reinhard倾向明亮的区域，在暗部不会很精细很有区分度
	- **曝光**
		- 通过曝光(Exposure)来调整场景的曝光等级
		- <mark>vec3 toneMapped = vec3(1.0) - exp(-hdrCol * exposure)</mark>
		- 更**小**的曝光能获得跟多的**亮部**细节，但是会**损失暗部细节**
		- 更**大**的曝光能获得更多的**暗部**细节，但是**亮部会过曝**
- 无HDR<br>![[OpenGL_HDR_无HDR.png]]
- HDR exposure(1.0)<br>![[OpenGL_HDR_exposure1.0.png]]
- HDR exposure(5.0)<br>![[OpenGL_HDR_exposure5.0.png]]
- HDR exposure(0.1)<br>![[OpenGL_HDR_exposure0.1.png]]

#### Bloom
- Bloom用于表达的光源和他的范围，让发光的区域产生光晕的效果，使一个明亮的物体真的有种明亮的感觉
- Bloom和HDR一起能够提供最好的效果，但是他们俩都可以独立使用，而不依赖对方，只是HDR能让Bloom的实现更简单
	- 有HDR的时候可以将Bloom的阈值设为1，而没有HDR的话需要将阈值设为小于1的数，这样会导致亮部容易变得很多，使得光晕效果过重
- ![[OpenGL_Bloom.png]]
- Bloom的实现思路
	- 渲染一个有光场景到带有浮点颜色缓冲(用于HDR)的帧缓冲![[OpenGL_Bloom步骤1.png]]
	- 通过设定一个阈值，提取出超过阈值亮度的片段![[OpenGL_Bloom步骤2.png]]
	- 对提取出来的片段进行模糊，Bloom效果的强度很大程度上是有被模糊的范围和强度所决定的![[OpenGL_Bloom步骤3.png]]
	- 将模糊过后的纹理添加到原来的HDR纹理上![[OpenGL_Bloom步骤4.png]]
- ###### 提取亮色
	- 由于需要从当前场景中提取两张图片，一张正常的场景渲染结果，一张通过设定阈值提取到的发光的片段的图片，每次可以使用一个不同的着色器渲染到不同的帧缓冲中，或者可以使用**MRT(Multiple Render Targets， 多渲染目标)** 的方法来一次在一个片段着色器中输出多张颜色缓冲给当前绑定的帧缓冲目标
		- 在创建帧缓冲以及创建并绑定帧缓冲的纹理附件时，<mark>GL_COLOR_ATTACHMENT0</mark>决定了当前帧缓冲有几个颜色缓冲。可以在使用<mark>GL_COLOR_ATTACHMENT1</mark>来为当前帧缓冲附加第二个纹理附件
		- 在片段着色器中，通过<mark>layout (location = 1) out vec4 BrightColor</mark>来将BrightColor输出到当前帧缓冲的第二个纹理附件中
		- 还需要告诉OpenGL他需要渲染到多个颜色缓冲，不然他就只会渲染到第一个颜色附件而忽略其他的颜色附件
			- <mark>GLuint attachments[2] = { GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1 };<br> glDrawBuffers(2, attachments);</mark>
- ###### 高斯模糊
	- 高斯模糊基于高斯曲线，中间的值达到最大化，随着距离的增加，两边的值不断减少
	- ![[OpenGL_高斯模糊.png]]
	- 为了大幅减少采样次数，减少性能开销，在使用高斯模糊的时候先对颜色缓冲的一个方向进行模糊，再在另一个帧缓冲中对已经进行了一个方向模糊的颜色缓冲进行另一个方向 的模糊
	- 片段着色器<br>![[OpenGL_高斯模糊片段着色器代码.png]]
	- 主程序里创建乒乓FBO<br>![[OpenGL_高斯模糊FBO代码.png]]
	- 渲染循环中进行交替模糊<br>![[OpenGL_高斯模糊渲染循环代码.png]]
		- 在进行交替模糊处理的时候，循环的第一次所采样的是HDRShader中渲染的提取了亮部的颜色缓冲，他会被模糊处理然后被渲染到乒乓FBO的第二个FBO
		- 在第二次循环时，采样的是第一次循环所渲染的在一个方向上进行了模糊处理的颜色缓冲，他会被在另一个方向上进行模糊处理然后渲染到乒乓FBO的第一个FBO
		- 随后的循环就是两个FBO互相交替采样并渲染，直到循环次数达到设置的模糊次数
- ###### 混合纹理
	- 在最终的默认帧缓冲的片段着色器中将一般渲染的HDR场景和进行了模糊处理的场景中的亮的部分进行相加混合并进行色调映射映射到LDR范围
- 效果一般-_- ![[OpenGL_Bloom效果.png]]

#### 延迟渲染(Defered Rendering)
- 前向渲染(Forward Rendering) 和 延迟渲染(Deffered Rendering)
	- 前向渲染会根据场景中的**所有光源**渲染一个物体，然后再渲染下一个物体，由于大量的模型的片段着色器的输出都会被之后的模型的输出所覆盖，所以前向渲染会在场景中因为景深的复杂度而浪费大量的片段着色器性能
	- 延迟渲染就是为了解决上面的问题。延时渲染包含两个处理阶段(Pass)
		- *每个阶段都有一个 "顶点 "和 "片段 "着色器*
		- 在一个阶段**几何处理阶段(Geometry Pass)** ，将会先渲染场景一次，获取到对象的各种几何信息并储存在G-buffer的纹理中，如位置向量、颜色向量、法线方向、镜面值(Specular values)。这些储存在G-buffer中的几何信息将会在之后用来做更复杂的光照计算
		- G-buffer的内容<br>![[OpenGL_延迟渲染_G-buffer.png]]
		- 在第二个阶段**光照处理阶段(Lighting Pass)**，将会使用储存在G-buffer中的几何数据对每一个片段计算场景光照
		- 延迟渲染的整个过程<br>![[OpenGL_延迟渲染流程.png]]
- 延迟渲染的优劣
	- **优点：**
		- 因为在计算光照时，所有的片段已经是最前面一层的片段，不需要计算被遮挡住的片段，所以可以省下很多无用的渲染调用
	- **缺点：**
		- 由于需要在内存中储存这个场景的各种数据，位置向量，颜色向量，法线方向等等，会消耗比较多的显存
		- 不支持混色，因为只有最前面的片段信息
		- 不能用MSAA
- ###### G-buffer
	- G-buffer所需要储存的数据有：
		- 片段世界位置向量
		- 片段世界空间法线方向
		- 片段颜色向量(贴图采样)
		- 片段镜面反射强度值(贴图采样，单通道)
	- 需要给每个数据在G-buffer中创建单独的纹理颜色缓冲附件
		- *片段颜色和镜面反射强度值可以组成一个4维向量并储存在同一张纹理颜色附件中 (RGB: 颜色，A: 镜面反射强度)*
		- 对于**向量数据 (法线方向，片段位置)**，需要使用更高精度的纹理颜色缓冲来储存 (16位 / 32位浮点数)，而对于**颜色数据**，使用默认的8位浮点数的纹理颜色缓冲就够了
- ###### 光照处理阶段
	- 从G-buffer中获取各种数据并像往常一样计算光照即可
- ###### 结合延迟渲染和前向渲染
	- 在延迟渲染之后，从gBuffer中读取场景的深度信息并写入到默认的帧缓冲中在进行后续的正向渲染，使正向渲染的物体能够正确的回应场景深度与物体间的遮挡关系![[OpenGL_延迟渲染+前向渲染.png]]
- ###### 光体积
	- 延迟渲染受欢迎的原因是它能够渲染大量的光源而不消耗大量的性能。但是延迟渲染本身并不能支持非常大量的光源，因为再不做任何优化的情况下还是需要在计算光照时对场景中的每个光源计算每个片段的光照分量
	- 真正让大量光源成为可能的是对延迟渲染管线的一个优化：**光体积(Light Volums)**
	- 通过计算出光的体积/半径/照射范围，可以只对在当前光源光照范围内的片段进行光照计算，而忽略掉范围外的，从而达到优化的效果
	- 光体积并不是最好的优化
	- **光的体积/半径的计算:**
		- 由于这个公式的光强永远等于不了0，所以使用5/256来代替0作为光照的最小强度
		- 太低的值会降低光体积的优化效果，而太高的值会让光照出现突然的断层
		- I<sub>max</sub>是光源的三个颜色分量中的最大值
		- x值即为光体积的半径

$$
\begin{align*}
\frac{5}{256}=\frac{I_{max}}{Attenuation}\\
\frac{5}{256}*Attenuation=I_{max}\\
5*Attenuation = I_{max}*256\\
Attuenuation = I_{max} * \frac{256}{5}\\
K_{c} + K_{l}*d + K_{q}*d^{2} = I_{max} * \frac{256}{5}\\
K_{q} * K_{l}*d + K_{c} - I_{max} * \frac{256}{5} = 0\\
x=\frac{-K_{l}+\sqrt{K_{l}^{2}-4*K_{q}*(\frac{K_{c}-I_{max}*256}{5})}}{2*K_{q}}
\end{align*}
$$
- ###### GPU的运行方式
	- 在片段着色器中使用`if`来判断光源到片段的距离是否超过了光体积的半径是**不能优化**渲染流程的
	- GPU中的着色器的运行是高度并行的，大部分的架构要求对于一个大的线程集合，GPU需要对它运行完全一样的着色器代码从而获得高效率。所以GPU会执行Shader里`if`所有的分支从而保证着色器运行都是一样的